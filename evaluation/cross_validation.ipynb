{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using 1 CUDA devices (GeForce GTX 1070)\n",
      "Device: cuda\n",
      "Using Seed: 34897567\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.insert(1, '../')  # to load from any submodule in the repo\n",
    "\n",
    "from utils import reader\n",
    "from utils import dpcrUtils as utils\n",
    "from utils import generator\n",
    "from utils import reconstructor\n",
    "from models import models\n",
    "\n",
    "from training import train_detector\n",
    "from training import train_predictor\n",
    "\n",
    "import torch\n",
    "import torch.nn\n",
    "\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import itertools\n",
    "import _pickle as cPickle\n",
    "from torchviz import make_dot\n",
    "\n",
    "device = utils.getDevice()\n",
    "print (\"Device:\", device)\n",
    "    \n",
    "torch.no_grad()\n",
    "\n",
    "seed_file = open('../utils/seed.txt', \"r\")\n",
    "seed = int(seed_file.read())\n",
    "seed_file.close()\n",
    "\n",
    "print (\"Using Seed:\", seed)\n",
    "    \n",
    "torch.manual_seed(seed)\n",
    "np.random.seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load complete!\n"
     ]
    }
   ],
   "source": [
    "validation_set = {\n",
    "    'multi_simple_shapes':{\n",
    "        'predictor':models.loadModel('../hpc/results/predictor_multi_simple_shapes_cnet_mish_radam_sd/2020-12-19_062318/predictor_checkpoints.t7', device=torch.device('cpu')),\n",
    "        'detector':models.loadModel('../hpc/results/detector_multi_simple_shapes_cnet_mish_radam_sd/2020-12-15_224339/detector_checkpoints.t7', device=torch.device('cpu'))\n",
    "    },\n",
    "    'multi_faces' :{\n",
    "        'predictor':models.loadModel('../hpc/results/predictor_multi_faces_cnet_mish_radam_sd/2020-12-15_224134/predictor_checkpoints.t7', device=torch.device('cpu')),\n",
    "        'detector':models.loadModel('../hpc/results/detector_multi_faces_cnet_mish_radam_sd/2020-12-09_074025/detector_checkpoints.t7', device=torch.device('cpu'))\n",
    "    },\n",
    "    'single_armadillo' :{\n",
    "        'predictor':models.loadModel('../hpc/results/predictor_single_armadillo_cnet_mish_radam_sd/2020-12-15_224123/predictor_checkpoints.t7', device=torch.device('cpu')),\n",
    "        'detector':models.loadModel('../hpc/results/detector_single_armadillo_cnet_mish_radam_sd/2020-12-15_224123/detector_checkpoints.t7', device=torch.device('cpu'))\n",
    "    },\n",
    "    'single_bunny' :{\n",
    "        'predictor':models.loadModel('../hpc/results/predictor_single_bunny_cnet_mish_radam/2020-12-31_171657/predictor_checkpoints.t7', device=torch.device('cpu')),\n",
    "        'detector':models.loadModel('../hpc/results/detector_single_bunny_cnet_mish_radam_sd/2020-12-08_110946/detector_checkpoints.t7', device=torch.device('cpu'))\n",
    "    },\n",
    "    'multi_cuboids' :{\n",
    "        'predictor':models.loadModel('../hpc/results/predictor_multi_cuboids_cnet_mish_radam_sd/2020-12-19_062203/predictor_checkpoints.t7', device=torch.device('cpu')),\n",
    "        'detector':models.loadModel('../hpc/results/detector_multi_cuboids_cnet_mish_radam_sd/2020-12-15_224131/detector_checkpoints.t7', device=torch.device('cpu'))\n",
    "    },\n",
    "    'multi_ellipsoids' :{\n",
    "        'predictor':models.loadModel('../hpc/results/predictor_multi_ellipsoids_cnet_mish_radam_sd/2020-12-19_062200/predictor_checkpoints.t7', device=torch.device('cpu')),\n",
    "        'detector':models.loadModel('../hpc/results/detector_multi_ellipsoids_cnet_mish_radam_sd/2020-12-15_224150/detector_checkpoints.t7', device=torch.device('cpu'))\n",
    "    },\n",
    "    'multi_polyhedrons' :{\n",
    "        'predictor':models.loadModel('../hpc/results/predictor_multi_cuboids_cnet_mish_radam_sd/2020-12-19_062203/predictor_checkpoints.t7', device=torch.device('cpu')),\n",
    "        'detector':models.loadModel('../hpc/results/detector_multi_polyhedrons_cnet_mish_radam_sd/2020-12-15_224129/detector_checkpoints.t7', device=torch.device('cpu'))\n",
    "    }\n",
    "\n",
    "}\n",
    "\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "print (\"Load complete!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dataset:  multi_simple_shapes ---------------------\n",
      "\n",
      "\n",
      "Reading validation models.. \n",
      "\n",
      "Processing model 1 of 9..\n",
      "   ..done! (1.3s)\n",
      "Processing model 2 of 9..\n",
      "   ..done! (0.1s)\n",
      "Processing model 3 of 9..\n",
      "   ..done! (0.1s)\n",
      "Processing model 4 of 9..\n",
      "   ..done! (0.1s)\n",
      "Processing model 5 of 9..\n",
      "   ..done! (0.1s)\n",
      "Processing model 6 of 9..\n",
      "   ..done! (0.1s)\n",
      "Processing model 7 of 9..\n",
      "   ..done! (0.1s)\n",
      "Processing model 8 of 9..\n",
      "   ..done! (0.1s)\n",
      "Processing model 9 of 9..\n",
      "   ..done! (0.1s)\n",
      "\n",
      "Generating validation samples for 9 models..\n",
      "   ..done! (0.2s) ---> #samples: 207\n",
      "\n",
      "Dataset:  multi_faces ---------------------\n",
      "\n",
      "\n",
      "Reading validation models.. \n",
      "\n",
      "Processing model 1 of 2..\n",
      "   ..done! (0.3s)\n",
      "Processing model 2 of 2..\n",
      "   ..done! (0.3s)\n",
      "\n",
      "Generating validation samples for 2 models..\n",
      "   ..done! (0.3s) ---> #samples: 244\n",
      "\n",
      "Dataset:  single_armadillo ---------------------\n",
      "\n",
      "\n",
      "Reading validation models.. \n",
      "\n",
      "Processing model 1 of 1..\n",
      "   ..done! (0.4s)\n",
      "\n",
      "Generating validation samples for 1 models..\n",
      "   ..done! (0.3s) ---> #samples: 245\n",
      "\n",
      "Dataset:  single_bunny ---------------------\n",
      "\n",
      "\n",
      "Reading validation models.. \n",
      "\n",
      "Processing model 1 of 1..\n",
      "   ..done! (0.3s)\n",
      "\n",
      "Generating validation samples for 1 models..\n",
      "   ..done! (0.2s) ---> #samples: 251\n",
      "\n",
      "Dataset:  multi_cuboids ---------------------\n",
      "\n",
      "\n",
      "Reading validation models.. \n",
      "\n",
      "Processing model 1 of 3..\n",
      "   ..done! (0.1s)\n",
      "Processing model 2 of 3..\n",
      "   ..done! (0.1s)\n",
      "Processing model 3 of 3..\n",
      "   ..done! (0.1s)\n",
      "\n",
      "Generating validation samples for 3 models..\n",
      "   ..done! (0.2s) ---> #samples: 237\n",
      "\n",
      "Dataset:  multi_ellipsoids ---------------------\n",
      "\n",
      "\n",
      "Reading validation models.. \n",
      "\n",
      "Processing model 1 of 3..\n",
      "   ..done! (0.1s)\n",
      "Processing model 2 of 3..\n",
      "   ..done! (0.1s)\n",
      "Processing model 3 of 3..\n",
      "   ..done! (0.1s)\n",
      "\n",
      "Generating validation samples for 3 models..\n",
      "   ..done! (0.2s) ---> #samples: 242\n",
      "\n",
      "Dataset:  multi_polyhedrons ---------------------\n",
      "\n",
      "\n",
      "Reading validation models.. \n",
      "\n",
      "Processing model 1 of 3..\n",
      "   ..done! (0.1s)\n",
      "Processing model 2 of 3..\n",
      "   ..done! (0.1s)\n",
      "Processing model 3 of 3..\n",
      "   ..done! (0.1s)\n",
      "\n",
      "Generating validation samples for 3 models..\n",
      "   ..done! (0.2s) ---> #samples: 244\n"
     ]
    }
   ],
   "source": [
    "for dataset in validation_set:\n",
    "\n",
    "    val_model_paths = ['../' + path for path in generator.getPaths()[dataset]['val']]\n",
    "    \n",
    "    hidden_range = (6,11)\n",
    "    iteration_range = (6,9)\n",
    "    \n",
    "    print (\"\\nDataset: \", dataset, \"---------------------\\n\")\n",
    "\n",
    "    print (\"\\nReading validation models.. \\n\")\n",
    "    val_models, val_knns = generator.readModels(val_model_paths, device=device, incrementKNNid = False)\n",
    "    \n",
    "    validation_size = int(30 / len(val_models))\n",
    "\n",
    "    print (\"\\nGenerating validation samples for %d models..\" % (len(val_models)))\n",
    "    start = time.time()\n",
    "    val_samples, val_sample_stats = generator.getSamples(val_knns, validation_size, hidden_range = hidden_range, iteration_range = iteration_range)\n",
    "    print (\"   ..done! (%.1fs) ---> #samples: %d\" % (time.time() - start, len(val_samples)))\n",
    "    \n",
    "    val_models_tensor = torch.cat(val_models)\n",
    "\n",
    "    # increment indices to concat\n",
    "    val_knn_sizes = [knn.size(0) for knn in val_knns]\n",
    "    val_knns = [knn + sum(val_knn_sizes[:i]) for (i, knn) in enumerate(val_knns)]\n",
    "\n",
    "    val_knns_tensor = torch.cat(val_knns).cpu()\n",
    "    \n",
    "    validation_set[dataset]['pts'] = val_models_tensor\n",
    "    validation_set[dataset]['knn'] = val_knns_tensor\n",
    "    validation_set[dataset]['samples'] = val_samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Measuring:  multi_simple_shapes\n",
      "AVG total time: 0.48798s\n",
      "AVG prediction time: 0.10731s\n",
      "AVG detection time: 0.01258s\n",
      "AVG corrector time: 0.00000s\n",
      "Measuring:  multi_faces\n",
      "AVG total time: 3.98132s\n",
      "AVG prediction time: 0.18099s\n",
      "AVG detection time: 0.02148s\n",
      "AVG corrector time: 0.00000s\n",
      "Measuring:  single_armadillo\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-5-b4a7dc90a2bb>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     35\u001b[0m                 \u001b[0mdevice\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdevice\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     36\u001b[0m                 \u001b[0mcorrector_stage\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 37\u001b[1;33m                 \u001b[0mreturnTimes\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     38\u001b[0m             )\n\u001b[0;32m     39\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Github\\Repos\\dpcr\\utils\\reconstructor.py\u001b[0m in \u001b[0;36mreconstruct\u001b[1;34m(data, predictor, detector, corrector, max_iters, t, verbose, device, corrector_stage, returnTimes)\u001b[0m\n\u001b[0;32m    203\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    204\u001b[0m             \u001b[1;31m# break if no new points are added\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 205\u001b[1;33m             \u001b[1;32mif\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m<\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    206\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0mverbose\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    207\u001b[0m                     \u001b[0mprint\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;34m\"No edge points detected\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "\n",
    "    for dataset in validation_set:\n",
    "\n",
    "        torch.cuda.empty_cache()\n",
    "\n",
    "        print (\"Measuring: \", dataset)\n",
    "\n",
    "        predictor = validation_set[dataset]['predictor'].to(device)\n",
    "        detector = validation_set[dataset]['detector'].to(device)\n",
    "\n",
    "        predictor.eval()\n",
    "        detector.eval()\n",
    "\n",
    "        val_pts = validation_set[dataset]['pts'].to(device)\n",
    "        val_samples = validation_set[dataset]['samples']\n",
    "        \n",
    "        total_prediction_time = 0\n",
    "        total_detection_time = 0\n",
    "        total_corrector_time = 0\n",
    "        total_time = 0\n",
    "        \n",
    "        for sample in val_samples:\n",
    "            \n",
    "            start = time.time()\n",
    "\n",
    "            prediction_time, detection_time, corrector_time = reconstructor.reconstruct(\n",
    "                val_pts[sample[:,0]],\n",
    "                predictor,\n",
    "                detector,\n",
    "                corrector = None,\n",
    "                max_iters = 10,\n",
    "                t = 0,\n",
    "                verbose=False,\n",
    "                device = device,\n",
    "                corrector_stage=5,\n",
    "                returnTimes=True\n",
    "            )\n",
    "            \n",
    "            end = time.time()\n",
    "            \n",
    "            total_time += end-start\n",
    "            total_prediction_time += prediction_time\n",
    "            total_detection_time += detection_time\n",
    "            total_corrector_time += corrector_time\n",
    "            \n",
    "        print (\"AVG total time: %.5fs\" % (total_time / len(val_samples)))\n",
    "        print (\"AVG prediction time: %.5fs\" % (total_prediction_time / len(val_samples)))\n",
    "        print (\"AVG detection time: %.5fs\" % (total_detection_time / len(val_samples)))\n",
    "        print (\"AVG corrector time: %.5fs\" % (total_corrector_time / len(val_samples)))\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "scrolled": false
   },
   "source": [
    "validation_results = {}\n",
    "\n",
    "perms_np = np.array(list(itertools.permutations(np.arange(6))))\n",
    "perms = torch.from_numpy(perms_np).long().to(device)\n",
    "\n",
    "with torch.no_grad():\n",
    "\n",
    "    for dataset in validation_set:\n",
    "        \n",
    "        torch.cuda.empty_cache()\n",
    "\n",
    "        validation_results[dataset] = {}\n",
    "\n",
    "        print (\"Validating: \", dataset)\n",
    "\n",
    "        predictor = validation_set[dataset]['predictor'].to(device)\n",
    "        detector = validation_set[dataset]['detector'].to(device)\n",
    "        \n",
    "        predictor.eval()\n",
    "        detector.eval()\n",
    "\n",
    "        for val_dataset in validation_set:\n",
    "            \n",
    "            torch.cuda.empty_cache()\n",
    "\n",
    "            validation_results[dataset][val_dataset] = {}\n",
    "\n",
    "            val_pts = validation_set[val_dataset]['pts'].to(device)\n",
    "            val_knn = validation_set[val_dataset]['knn']\n",
    "            val_samples = validation_set[val_dataset]['samples']\n",
    "\n",
    "            val_neighbors_dirs = (val_pts[val_knn] - val_pts[:, None, :]).to(device)\n",
    "\n",
    "            av_c1_freq = sum([torch.sum(sample[:,1]).item() for sample in val_samples]) / sum([sample.size(0) for sample in val_samples])\n",
    "            class_weights = torch.tensor([av_c1_freq, 1-av_c1_freq]).float().to(device)\n",
    "\n",
    "            print (\"   Validating for: \", val_dataset)\n",
    "\n",
    "            start = time.time()\n",
    "            det_loss, det_acc, det_acc_c0, det_acc_c1 = train_detector.getTestLoss(val_pts, val_samples, detector, class_weights)\n",
    "\n",
    "            print (\"      -> detector done! (%.1f)\" % (time.time() - start))\n",
    "            print (\"         Detector Loss:\", det_loss)\n",
    "            print (\"         Detector Acc:\", det_acc)\n",
    "            print (\"         Detector C0 Acc:\", det_acc_c0)\n",
    "            print (\"         Detector C1 Acc:\", det_acc_c1)\n",
    "\n",
    "            start = time.time()\n",
    "            pred_loss = train_predictor.val_loss = train_predictor.getTestLoss(val_pts, val_samples, predictor, val_neighbors_dirs, perms, torch.nn.MSELoss(reduction='mean'))\n",
    "\n",
    "            print (\"      -> predictor done! (%.1f)\" % (time.time() - start))\n",
    "            print (\"         Predictor Loss:\", pred_loss)\n",
    "\n",
    "            print (\"\")\n",
    "\n",
    "            validation_results[dataset][val_dataset]['det_loss'] = det_loss\n",
    "            validation_results[dataset][val_dataset]['det_acc'] = det_acc\n",
    "            validation_results[dataset][val_dataset]['det_acc_c0'] = det_acc_c0\n",
    "            validation_results[dataset][val_dataset]['det_acc_c1'] = det_acc_c1\n",
    "            validation_results[dataset][val_dataset]['pred_loss'] = pred_loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'multi_simple_shapes': {}}"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "validation_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.6.2 64-bit",
   "language": "python",
   "name": "python36264bit0676f2f61ede4885a79bdf760204de6d"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
